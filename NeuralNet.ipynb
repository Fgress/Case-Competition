{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d3cf3b-c9ff-4e47-811a-49a45343cfef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd8752f-2c69-4dc0-b720-db9a72598f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7d7521-4307-4321-adf6-e7852badaae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5491 - loss: 0.6849 - val_accuracy: 0.5850 - val_loss: 0.6508\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6030 - loss: 0.6463 - val_accuracy: 0.5920 - val_loss: 0.6480\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 0.6487 - val_accuracy: 0.5960 - val_loss: 0.6470\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.6459 - val_accuracy: 0.5900 - val_loss: 0.6478\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6198 - loss: 0.6374 - val_accuracy: 0.6010 - val_loss: 0.6526\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 0.6391 - val_accuracy: 0.6000 - val_loss: 0.6469\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6275 - loss: 0.6303 - val_accuracy: 0.5930 - val_loss: 0.6481\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6374 - loss: 0.6251 - val_accuracy: 0.5940 - val_loss: 0.6514\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6444 - loss: 0.6257 - val_accuracy: 0.6000 - val_loss: 0.6496\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6488 - loss: 0.6281 - val_accuracy: 0.6080 - val_loss: 0.6491\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5943 - loss: 0.6616\n",
      "Test accuracy: 0.602400004863739\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the categorical variables\n",
    "categorical_features = ['AI_Response_Time', 'Change_in_Usage_Patterns', 'AI_Interaction_Level']\n",
    "one_hot_encoder = ColumnTransformer(transformers=[\n",
    "    ('one_hot', OneHotEncoder(drop='first'), categorical_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "X_train = one_hot_encoder.fit_transform(train_data.drop(columns=['ID', 'Customer_Churn']))\n",
    "y_train = train_data['Customer_Churn']\n",
    "X_test = one_hot_encoder.transform(test_data.drop(columns=['ID', 'Customer_Churn']))\n",
    "y_test = test_data['Customer_Churn']\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "855548c4-16b8-454d-b851-adf73ae512b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5575 - loss: 1.2327 - val_accuracy: 0.5860 - val_loss: 0.9717\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5996 - loss: 0.9148 - val_accuracy: 0.5880 - val_loss: 0.8033\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6020 - loss: 0.7868 - val_accuracy: 0.5930 - val_loss: 0.7238\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 0.7147 - val_accuracy: 0.6030 - val_loss: 0.6911\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6889 - val_accuracy: 0.6000 - val_loss: 0.6706\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5981 - loss: 0.6742 - val_accuracy: 0.6000 - val_loss: 0.6637\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6098 - loss: 0.6604 - val_accuracy: 0.5930 - val_loss: 0.6589\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5866 - loss: 0.6666 - val_accuracy: 0.5970 - val_loss: 0.6573\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5959 - loss: 0.6662 - val_accuracy: 0.6080 - val_loss: 0.6546\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5916 - loss: 0.6582 - val_accuracy: 0.6040 - val_loss: 0.6533\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5725 - loss: 0.6611\n",
      "Test accuracy: 0.5799999833106995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ce0dc9-df31-4203-a16a-29d843925ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Test accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1e4f8-3bb7-4602-a4ed-2e77e898e226",
   "metadata": {},
   "source": [
    "## Reduce model with neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26ec14c-8494-43e2-82cd-5c5c33fc1b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd0f603-d59b-4d2d-a170-64faada163c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the unwanted features\n",
    "train_data_reduced = train_data.drop(columns=['AI_Personalization_Effectiveness', 'AI_Response_Time'])\n",
    "test_data_reduced = test_data.drop(columns=['AI_Personalization_Effectiveness', 'AI_Response_Time'])\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "categorical_features = ['Change_in_Usage_Patterns', 'AI_Interaction_Level']  # Update this list as needed\n",
    "one_hot_encoder = ColumnTransformer(transformers=[\n",
    "    ('one_hot', OneHotEncoder(drop='first'), categorical_features)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "X_train_reduced = one_hot_encoder.fit_transform(train_data_reduced.drop(columns=['ID', 'Customer_Churn']))\n",
    "y_train = train_data_reduced['Customer_Churn']\n",
    "X_test_reduced = one_hot_encoder.transform(test_data_reduced.drop(columns=['ID', 'Customer_Churn']))\n",
    "y_test = test_data_reduced['Customer_Churn']\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_reduced = scaler.fit_transform(X_train_reduced)\n",
    "X_test_reduced = scaler.transform(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad71698-3b09-4ddf-82d3-8fab6bfe8fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5702 - loss: 0.6752 - val_accuracy: 0.5900 - val_loss: 0.6543\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5987 - loss: 0.6558 - val_accuracy: 0.6070 - val_loss: 0.6422\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6085 - loss: 0.6462 - val_accuracy: 0.6100 - val_loss: 0.6412\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6001 - loss: 0.6464 - val_accuracy: 0.6090 - val_loss: 0.6427\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6243 - loss: 0.6428 - val_accuracy: 0.6010 - val_loss: 0.6452\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6371 - loss: 0.6375 - val_accuracy: 0.6100 - val_loss: 0.6419\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6269 - loss: 0.6363 - val_accuracy: 0.6030 - val_loss: 0.6458\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6329 - loss: 0.6307 - val_accuracy: 0.6060 - val_loss: 0.6414\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6252 - loss: 0.6359 - val_accuracy: 0.6100 - val_loss: 0.6434\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 0.6392 - val_accuracy: 0.6060 - val_loss: 0.6424\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5808 - loss: 0.6587\n",
      "Test accuracy: 0.5943999886512756\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_reduced.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reduced, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test_reduced, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04c280ce-5c9a-432e-98cc-c1ca07fa09e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5445 - loss: 0.7107 - val_accuracy: 0.5890 - val_loss: 0.6618\n",
      "Epoch 2/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5709 - loss: 0.6786 - val_accuracy: 0.5890 - val_loss: 0.6567\n",
      "Epoch 3/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5715 - loss: 0.6720 - val_accuracy: 0.5930 - val_loss: 0.6497\n",
      "Epoch 4/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5834 - loss: 0.6662 - val_accuracy: 0.6030 - val_loss: 0.6526\n",
      "Epoch 5/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5815 - loss: 0.6658 - val_accuracy: 0.6010 - val_loss: 0.6464\n",
      "Epoch 6/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5744 - loss: 0.6646 - val_accuracy: 0.5840 - val_loss: 0.6473\n",
      "Epoch 7/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5859 - loss: 0.6675 - val_accuracy: 0.6000 - val_loss: 0.6450\n",
      "Epoch 8/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5947 - loss: 0.6588 - val_accuracy: 0.5820 - val_loss: 0.6459\n",
      "Epoch 9/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5803 - loss: 0.6550 - val_accuracy: 0.5870 - val_loss: 0.6462\n",
      "Epoch 10/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5946 - loss: 0.6563 - val_accuracy: 0.5990 - val_loss: 0.6464\n",
      "Epoch 11/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5797 - loss: 0.6536 - val_accuracy: 0.5970 - val_loss: 0.6469\n",
      "Epoch 12/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5989 - loss: 0.6547 - val_accuracy: 0.6020 - val_loss: 0.6466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd44cb07ee0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_reduced.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.fit(X_train_reduced, y_train, epochs=50, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a875ce-b436-4b14-b8bf-39b1d34599d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5971 - loss: 0.6538\n",
      "Test accuracy: 0.5935999751091003\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test_reduced, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06cf3b6f-397e-4b0c-bc45-99df68cc1414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5340 - loss: 1.5516 - val_accuracy: 0.5920 - val_loss: 1.0674\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5770 - loss: 1.0072 - val_accuracy: 0.5880 - val_loss: 0.8322\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5840 - loss: 0.8143 - val_accuracy: 0.5900 - val_loss: 0.7361\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5799 - loss: 0.7368 - val_accuracy: 0.5930 - val_loss: 0.6916\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5826 - loss: 0.7008 - val_accuracy: 0.5930 - val_loss: 0.6735\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5782 - loss: 0.6822 - val_accuracy: 0.5890 - val_loss: 0.6660\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5694 - loss: 0.6742 - val_accuracy: 0.5920 - val_loss: 0.6590\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5939 - loss: 0.6645 - val_accuracy: 0.6060 - val_loss: 0.6592\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5876 - loss: 0.6684 - val_accuracy: 0.5960 - val_loss: 0.6577\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5799 - loss: 0.6667 - val_accuracy: 0.6010 - val_loss: 0.6562\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 0.6654 - val_accuracy: 0.5940 - val_loss: 0.6597\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5841 - loss: 0.6720 - val_accuracy: 0.5950 - val_loss: 0.6545\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5890 - loss: 0.6664 - val_accuracy: 0.5900 - val_loss: 0.6567\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5823 - loss: 0.6723 - val_accuracy: 0.5930 - val_loss: 0.6576\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5963 - loss: 0.6647 - val_accuracy: 0.5960 - val_loss: 0.6562\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5848 - loss: 0.6665 - val_accuracy: 0.5990 - val_loss: 0.6560\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5818 - loss: 0.6616 - val_accuracy: 0.5940 - val_loss: 0.6532\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5772 - loss: 0.6642 - val_accuracy: 0.5970 - val_loss: 0.6587\n",
      "Epoch 19/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5974 - loss: 0.6603 - val_accuracy: 0.5960 - val_loss: 0.6548\n",
      "Epoch 20/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5940 - loss: 0.6571 - val_accuracy: 0.6020 - val_loss: 0.6589\n",
      "Epoch 21/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5798 - loss: 0.6685 - val_accuracy: 0.5970 - val_loss: 0.6521\n",
      "Epoch 22/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5791 - loss: 0.6659 - val_accuracy: 0.6030 - val_loss: 0.6546\n",
      "Epoch 23/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5854 - loss: 0.6685 - val_accuracy: 0.5970 - val_loss: 0.6535\n",
      "Epoch 24/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6034 - loss: 0.6619 - val_accuracy: 0.6000 - val_loss: 0.6535\n",
      "Epoch 25/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5851 - loss: 0.6685 - val_accuracy: 0.6030 - val_loss: 0.6523\n",
      "Epoch 26/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 0.6645 - val_accuracy: 0.6000 - val_loss: 0.6513\n",
      "Epoch 27/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6013 - loss: 0.6604 - val_accuracy: 0.5950 - val_loss: 0.6544\n",
      "Epoch 28/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 0.6560 - val_accuracy: 0.5960 - val_loss: 0.6553\n",
      "Epoch 29/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5912 - loss: 0.6603 - val_accuracy: 0.5920 - val_loss: 0.6546\n",
      "Epoch 30/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5961 - loss: 0.6632 - val_accuracy: 0.5880 - val_loss: 0.6510\n",
      "Epoch 31/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 0.6713 - val_accuracy: 0.5920 - val_loss: 0.6513\n",
      "Epoch 32/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 0.6701 - val_accuracy: 0.5890 - val_loss: 0.6509\n",
      "Epoch 33/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5820 - loss: 0.6690 - val_accuracy: 0.5970 - val_loss: 0.6511\n",
      "Epoch 34/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5925 - loss: 0.6639 - val_accuracy: 0.5940 - val_loss: 0.6516\n",
      "Epoch 35/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5877 - loss: 0.6596 - val_accuracy: 0.6050 - val_loss: 0.6517\n",
      "Epoch 36/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5863 - loss: 0.6649 - val_accuracy: 0.5920 - val_loss: 0.6525\n",
      "Epoch 37/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5706 - loss: 0.6663 - val_accuracy: 0.5910 - val_loss: 0.6503\n",
      "Epoch 38/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5845 - loss: 0.6598 - val_accuracy: 0.5880 - val_loss: 0.6530\n",
      "Epoch 39/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6047 - loss: 0.6593 - val_accuracy: 0.5860 - val_loss: 0.6508\n",
      "Epoch 40/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5732 - loss: 0.6707 - val_accuracy: 0.5980 - val_loss: 0.6505\n",
      "Epoch 41/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5830 - loss: 0.6644 - val_accuracy: 0.6000 - val_loss: 0.6591\n",
      "Epoch 42/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5850 - loss: 0.6632 - val_accuracy: 0.5880 - val_loss: 0.6514\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.6596\n",
      "Test accuracy: 0.5784000158309937\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_reduced.shape[1],),\n",
    "                 kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.fit(X_train_reduced, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
    "          callbacks=[early_stopping])\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test_reduced, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438fcb1-9a21-4216-a362-d7326c1de159",
   "metadata": {},
   "source": [
    "## Hypertuning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fc6a04c-9b64-426b-933f-c7c5d82ef461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.28.2)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (3.0.5)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (1.23.5)\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras-tuner) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfaeba37-8138-4955-93be-961e1135eba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 11s]\n",
      "val_accuracy: 0.597000002861023\n",
      "\n",
      "Best val_accuracy So Far: 0.6159999966621399\n",
      "Total elapsed time: 00h 04m 15s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 384 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5761 - loss: 0.6840 - val_accuracy: 0.6030 - val_loss: 0.6481\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5728 - loss: 0.6676 - val_accuracy: 0.6000 - val_loss: 0.6436\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6041 - loss: 0.6519 - val_accuracy: 0.6000 - val_loss: 0.6431\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5972 - loss: 0.6593 - val_accuracy: 0.6130 - val_loss: 0.6419\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6070 - loss: 0.6511 - val_accuracy: 0.6050 - val_loss: 0.6393\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6118 - loss: 0.6446 - val_accuracy: 0.6040 - val_loss: 0.6424\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6072 - loss: 0.6526 - val_accuracy: 0.5930 - val_loss: 0.6440\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6113 - loss: 0.6484 - val_accuracy: 0.6070 - val_loss: 0.6413\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6033 - loss: 0.6485 - val_accuracy: 0.6100 - val_loss: 0.6442\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6173 - loss: 0.6374 - val_accuracy: 0.5940 - val_loss: 0.6475\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6078 - loss: 0.6553 - val_accuracy: 0.6120 - val_loss: 0.6412\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6243 - loss: 0.6399 - val_accuracy: 0.5910 - val_loss: 0.6507\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6055 - loss: 0.6503 - val_accuracy: 0.6030 - val_loss: 0.6393\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6121 - loss: 0.6490 - val_accuracy: 0.5980 - val_loss: 0.6428\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6059 - loss: 0.6448 - val_accuracy: 0.6250 - val_loss: 0.6414\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6359 - loss: 0.6335 - val_accuracy: 0.6090 - val_loss: 0.6401\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6436 - loss: 0.6303 - val_accuracy: 0.6030 - val_loss: 0.6454\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6082 - loss: 0.6442 - val_accuracy: 0.6040 - val_loss: 0.6424\n",
      "Epoch 19/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6308 - loss: 0.6321 - val_accuracy: 0.6020 - val_loss: 0.6447\n",
      "Epoch 20/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6176 - loss: 0.6459 - val_accuracy: 0.5970 - val_loss: 0.6463\n",
      "Epoch 21/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6258 - loss: 0.6366 - val_accuracy: 0.6110 - val_loss: 0.6442\n",
      "Epoch 22/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6400 - loss: 0.6317 - val_accuracy: 0.5990 - val_loss: 0.6466\n",
      "Epoch 23/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 0.6351 - val_accuracy: 0.6100 - val_loss: 0.6420\n",
      "Epoch 24/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6291 - loss: 0.6405 - val_accuracy: 0.6070 - val_loss: 0.6439\n",
      "Epoch 25/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6357 - loss: 0.6346 - val_accuracy: 0.6090 - val_loss: 0.6433\n",
      "Epoch 26/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6103 - loss: 0.6398 - val_accuracy: 0.6030 - val_loss: 0.6453\n",
      "Epoch 27/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6577 - loss: 0.6248 - val_accuracy: 0.6130 - val_loss: 0.6433\n",
      "Epoch 28/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6276 - loss: 0.6345 - val_accuracy: 0.6110 - val_loss: 0.6438\n",
      "Epoch 29/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6325 - loss: 0.6312 - val_accuracy: 0.6090 - val_loss: 0.6457\n",
      "Epoch 30/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6206 - loss: 0.6403 - val_accuracy: 0.6090 - val_loss: 0.6442\n",
      "Epoch 31/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6282 - loss: 0.6280 - val_accuracy: 0.6150 - val_loss: 0.6453\n",
      "Epoch 32/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6301 - loss: 0.6338 - val_accuracy: 0.6100 - val_loss: 0.6499\n",
      "Epoch 33/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6272 - loss: 0.6300 - val_accuracy: 0.6140 - val_loss: 0.6485\n",
      "Epoch 34/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6382 - loss: 0.6208 - val_accuracy: 0.6070 - val_loss: 0.6471\n",
      "Epoch 35/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6381 - loss: 0.6291 - val_accuracy: 0.6020 - val_loss: 0.6479\n",
      "Epoch 36/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6503 - loss: 0.6215 - val_accuracy: 0.6060 - val_loss: 0.6488\n",
      "Epoch 37/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6291 - loss: 0.6406 - val_accuracy: 0.6180 - val_loss: 0.6482\n",
      "Epoch 38/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6392 - loss: 0.6239 - val_accuracy: 0.6020 - val_loss: 0.6506\n",
      "Epoch 39/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6382 - loss: 0.6284 - val_accuracy: 0.6000 - val_loss: 0.6494\n",
      "Epoch 40/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6359 - loss: 0.6239 - val_accuracy: 0.6060 - val_loss: 0.6498\n",
      "Epoch 41/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6539 - loss: 0.6238 - val_accuracy: 0.6000 - val_loss: 0.6505\n",
      "Epoch 42/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6544 - loss: 0.6140 - val_accuracy: 0.6270 - val_loss: 0.6463\n",
      "Epoch 43/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6390 - loss: 0.6248 - val_accuracy: 0.6190 - val_loss: 0.6461\n",
      "Epoch 44/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6359 - loss: 0.6266 - val_accuracy: 0.6080 - val_loss: 0.6497\n",
      "Epoch 45/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6368 - loss: 0.6266 - val_accuracy: 0.6190 - val_loss: 0.6492\n",
      "Epoch 46/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6258 - loss: 0.6351 - val_accuracy: 0.6280 - val_loss: 0.6496\n",
      "Epoch 47/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6398 - loss: 0.6247 - val_accuracy: 0.6090 - val_loss: 0.6498\n",
      "Epoch 48/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6504 - loss: 0.6223 - val_accuracy: 0.6050 - val_loss: 0.6524\n",
      "Epoch 49/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6448 - loss: 0.6199 - val_accuracy: 0.6140 - val_loss: 0.6504\n",
      "Epoch 50/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6285 - loss: 0.6260 - val_accuracy: 0.6050 - val_loss: 0.6538\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(X_train_reduced.shape[1],)))\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Add more hidden layers with tuned number of units\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        model.add(layers.Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "                               activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train_reduced, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_reduced, y_train, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bdde4bf-6f52-4b8e-8555-d84f0c603c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 0.6769\n",
      "Test accuracy: 0.5856000185012817\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test_reduced, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efc69636-cbdb-4117-a5b6-3457831a1f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Test accuracy: 0.5856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test_reduced)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf892e1-ec12-4c21-9d27-6b3be0123115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
